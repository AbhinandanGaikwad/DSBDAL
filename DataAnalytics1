from sklearn.model_selection import train_test_split
from sklearn import metrics


import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

%matplotlib inline
import warnings
warnings.filterwarnings(action = 'ignore')

df = pd.read_csv('housing_data.csv')
df

names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD','TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']

df.head()

df.shape

df.info()

df.isnull().sum()

for feature in names:
 df[feature].fillna(df[feature].median(), inplace = True)
df.isnull().sum()

plt.figure(figsize=(12,12))
 sns.heatmap(data=df.corr().round(2), annot=True, cmap='coolwarm', linewidths=0.2, square=True)

df1= df[['RM','TAX','PTRATIO','LSTAT','MEDV']] 
df1

sns.pairplot(df1)

d = df1.describe().round(2)
d

plt.figure(figsize=(20,3))
plt.subplot(1,2,1)
sns.boxplot(df1['MEDV'], color='#005030')
plt.title("BoxPlot Of MEDV")
plt.subplot(1,2,2)
sns.distplot(a=df1.MEDV, color='#500050')
plt.title("Distribution Plot Of MEDV")
plt.show()

#IQR
Q3 = d['MEDV']['75%']
Q1 = d['MEDV']['25%']
IQR = Q3- Q1
ub = Q3 + 1.5*IQR
lb = Q1- 1.5*IQR

df1[df1['MEDV'] > ub]

print(f"Shape of the dataset before removing outlier {df1.shape} ")

df2 = df1[~(df1['MEDV'] == 50)] 

print(f"Shape of the dataset after removing outlier {df2.shape} ")

plt.figure(figsize=(20,3))
plt.subplot(1,2,1)
sns.boxplot(df2['MEDV'], color='#005030')
plt.title("BoxPlot Of MEDV")
plt.subplot(1,2,2)
sns.distplot(a=df2.MEDV, color='#500050')
plt.title("Distribution Plot Of MEDV")
print("AFTER REMOVING OUTLIERS")
plt.show()

plt.figure(figsize=(20,3))
plt.subplot(1,3,1) # 1row, 3 cols, this is 1st col
sns.boxplot(df2['TAX'], color='#005030')
plt.title("BoxPlot Of TAX")
plt.subplot(1,3,2)
sns.distplot(a=df2.TAX, color='#500050')
plt.title("Distribution Plot Of TAX")
plt.subplot(1,3,3)
sns.scatterplot(x=df2.TAX,y=df2.MEDV)
plt.title("ScatterPlot Plot Of TAX vs MEDV")
plt.show()

temp_df = df2[df1['TAX'] > 600].sort_values(['RM', 'MEDV'])
temp_df

temp_df.shape

temp_df.describe()

tax_10 = df2[(df2['TAX'] < 600) & (df2['LSTAT'] >= 0) & (df2['LSTAT'] < 10)]['TAX'].mean()
tax_20 = df2[(df2['TAX'] < 600) & (df2['LSTAT'] >= 10) & (df2['LSTAT'] < 20)]['TAX'].mean()
tax_30 = df2[(df2['TAX'] < 600) & (df2['LSTAT'] >= 20) & (df2['LSTAT'] < 30)]['TAX'].mean()
tax_40 = df2[(df2['TAX'] < 600) & (df2['LSTAT'] >= 30)]['TAX'].mean()
indexes = list(df2.index)

for i in indexes:
 if(0 <= df2['LSTAT'][i] < 10):
    df2.at[i,'TAX'] = tax_10
 elif(10 <= df2['LSTAT'][i] < 20):
    df2.at[i,'TAX'] = tax_20
 elif(20 <= df2['LSTAT'][i] < 30):
    df2.at[i,'TAX'] = tax_30
 elif(30 <= df2['LSTAT'][i] ):
    df2.at[i,'TAX'] = tax_40
print("Value imputed successfully.")

df2[df2['TAX'] > 600]['TAX'].count()

sns.distplot(a=df2.TAX, color='#500050')
plt.title("Distribution Plot Of TAX after replacing extreme values")
plt.show()

df2.shape

df2.describe()

plt.figure(figsize=(20,3))
plt.subplot(1,3,1) # 1row, 3 cols, this is 1st col
sns.boxplot(df2['PTRATIO'], color='#005030')
plt.title("BoxPlot Of PTRATIO")
plt.subplot(1,3,2)
sns.distplot(a=df2.PTRATIO, color='#500050')
plt.title("Distribution Plot Of PTRATIO")
plt.subplot(1,3,3)
sns.scatterplot(x=df2.PTRATIO,y=df2.MEDV)
plt.title("ScatterPlot Plot Of PTRATIO vs MEDV")
plt.show()

plt.figure(figsize=(20,3))
plt.subplot(1,3,1) # 1row, 3 cols, this is 1st col
sns.boxplot(df2['LSTAT'], color='#005030')
plt.title("BoxPlot Of LSTAT")
plt.subplot(1,3,2)
sns.distplot(a=df2.LSTAT, color='#500050')
plt.title("Distribution Plot Of LSTAT")
plt.subplot(1,3,3)
sns.scatterplot(x=df2.LSTAT,y=df2.MEDV)
plt.title("ScatterPlot Plot Of LSTAT vs MEDV")
plt.show()

df2[df2['LSTAT'] > 30].sort_values(by= 'LSTAT')

Q3 = d['LSTAT']['75%']
Q1 = d['LSTAT']['25%']
IQR = Q3- Q1
ub = Q3 + 1.5*IQR
lb = Q1- 1.5*IQR
df2[df2['LSTAT'] > ub].sort_values(by= 'LSTAT')

plt.figure(figsize=(20,3))
plt.subplot(1,3,1) # 1row, 3 cols, this is 1st col
sns.boxplot(df2['RM'], color='#005030')
plt.title("BoxPlot Of RM")
plt.subplot(1,3,2)
sns.distplot(a=df2.RM, color='#500050')
plt.title("Distribution Plot Of RM")
plt.subplot(1,3,3)
sns.scatterplot(x=df2.RM,y=df2.MEDV)
plt.title("ScatterPlot Plot Of RM vs MEDV")
plt.show()

Q3 = d['RM']['75%']
Q1 = d['RM']['25%']
IQR = Q3- Q1
ub = Q3 + 1.5*IQR
lb = Q1- 1.5*IQR
df2[df2['RM'] < lb].sort_values(by= ['RM','MEDV'])

print(f"Shape of the dataset before removing outlier {df2.shape} ")
df3 = df2.drop(axis=0,index =[365,367]) # removing rows with these indices
print(f"Shape of the dataset after removing outlier {df3.shape} ")

df3[df3['RM'] > ub].sort_values(by= ['RM','MEDV'])

print(f"Shape of the dataset before removing outlier {df3.shape} ")

df3 = df3.drop(axis=0,index = 364) # gadbad in index 364
print(f"Shape of the dataset after removing outlier {df3.shape} ")

df3[df3['RM'] > ub].sort_values(by= ['RM','MEDV'])

df3

X = df3.iloc[:,0:4].values # REST ALL FOUR HERE
y = df3.iloc[:,-1:].values # MEDV

print(f"Shape of Dependent Variable X = {X.shape}")
print(f"Shape of Independent Variable y = {y.shape}")

def FeatureScaling(X):
 """
 is function takes an array as an input, which needs to be scaled down.
 Apply Standardization technique to it and scale down the features with mean = 0 and standard deviation = 1
 Input <- 2 dimensional numpy array
 Returns-> Numpy array after applying Feature Scaling
 """
 # Z score converting into 0's or 1's form to work on this big range of data
 mean = np.mean(X,axis=0) # ALL ROWS MEAN
 std = np.std(X,axis=0)
 for i in range(X.shape[1]):
 X[:,i] = (X[:,i]-mean[i])/std[i]
 return X

X = FeatureScaling(X)
X

m,n = X.shape 
X = np.append(arr=np.ones((m,1)),values=X,axis=1)
X

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state = 42)
print(f"Shape of X_train = {X_train.shape}")
print(f"Shape of X_test = {X_test.shape}")
print(f"Shape of y_train = {y_train.shape}")
print(f"Shape of y_test = {y_test.shape}")

def ComputeCost(X,y,theta):
 """
 This function takes three inputs and uses the Cost Function to determine the cost (basically error of prediction vs
 actual values)
 Cost Function: Sum of square of error in predicted values divided by numberof data points in the set
 J = 1/(2*m) * Summation(Square(Predicted values- Actual values))
 Input <- Take three numpy array X,y and theta
 Return-> The cost calculated from the Cost Function
 """
 m=X.shape[0] #number of data points in the set
 J = (1/(2*m)) * np.sum((X.dot(theta)- y)**2)
 return J

def GradientDescent(X,y,theta,alpha,no_of_iters):
 m=X.shape[0]
 J_Cost = []
 for i in range(no_of_iters):
 error = np.dot(X.transpose(),(X.dot(theta)-y))
 theta = theta- alpha * (1/m) * error
 J_Cost.append(ComputeCost(X,y,theta))
 return theta, np.array(J_Cost)

iters = 1000 # differential equations 1000 times krenge to check
alpha1 = 0.001
theta1 = np.zeros((X_train.shape[1],1))
theta1, J_Costs1 = GradientDescent(X_train,y_train,theta1,alpha1,iters)
alpha2 = 0.003
theta2 = np.zeros((X_train.shape[1],1))
theta2, J_Costs2 = GradientDescent(X_train,y_train,theta2,alpha2,iters)
alpha3 = 0.01
theta3 = np.zeros((X_train.shape[1],1))
theta3, J_Costs3 = GradientDescent(X_train,y_train,theta3,alpha3,iters)
alpha4 = 0.03
theta4 = np.zeros((X_train.shape[1],1))
theta4, J_Costs4 = GradientDescent(X_train,y_train,theta4,alpha4,iters)

plt.figure(figsize=(8,5))
plt.plot(J_Costs1,label = 'alpha = 0.001')
plt.plot(J_Costs2,label = 'alpha = 0.003')
plt.plot(J_Costs3,label = 'alpha = 0.01')
plt.plot(J_Costs4,label = 'alpha = 0.03')
plt.title('Convergence of Gradient Descent for different values of alpha')
plt.xlabel('No. of iterations')
plt.ylabel('Cost')
plt.legend()
plt.show()

theta4

def Predict(X,theta):
 """
 This function predicts the result for the unseen data
 """
 y_pred = X.dot(theta)
 return y_pred

y_pred = Predict(X_test,theta4)
y_pred[:5]

y_pred

plt.scatter(x=y_test,y=y_pred,alpha=0.5)
plt.xlabel('y_test',size=12)
plt.ylabel('y_pred',size=12)
plt.title('Predicited Values vs Original Values (Test Set)',size=15)
plt.show()